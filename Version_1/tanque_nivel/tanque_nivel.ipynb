{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploraci√≥n: DQN para Control de Tanque\n",
    "\n",
    "Este notebook permite explorar y probar el agente DQN de forma interactiva antes del entrenamiento completo.\n",
    "\n",
    "## Objetivos:\n",
    "- Verificar que el simulador funciona correctamente\n",
    "- Probar agentes en un entorno sencillo\n",
    "- Ajustar hiperpar√°metros interactivamente\n",
    "- Visualizar resultados inmediatamente\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports y Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports completados\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Agregar paths para importar m√≥dulos del proyecto\n",
    "sys.path.append('../..')\n",
    "\n",
    "from simulations.tanque_nivel.tanque_simulator import TankLevelSimulator\n",
    "from agent_valeria.DQN.dqn_agent import DQN_Agent\n",
    "from environment.universal_pid_env import UniversalPIDControlEnv\n",
    "\n",
    "# Configurar matplotlib para notebooks\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"Imports completados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TankLevelSimulator.__init__() got an unexpected keyword argument 'dead_band'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## Crear Entorno y Agente DQN\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Crear simulador h√≠brido de tanque\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m tank \u001b[38;5;241m=\u001b[39m TankLevelSimulator(\n\u001b[1;32m      5\u001b[0m     tank_area\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2.0\u001b[39m,           \u001b[38;5;66;03m# m¬≤ - √Årea del tanque\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     max_height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5.0\u001b[39m,          \u001b[38;5;66;03m# m - Altura m√°xima\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     max_inflow\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10.0\u001b[39m,         \u001b[38;5;66;03m# L/s - Caudal m√°ximo\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     outflow_coeff\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2.0\u001b[39m,       \u001b[38;5;66;03m# Coeficiente de salida\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     dt\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m,                  \u001b[38;5;66;03m# s - Paso de tiempo\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     noise_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.02\u001b[39m,        \u001b[38;5;66;03m# Ruido en medici√≥n\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     dead_band\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,           \u001b[38;5;66;03m# m - Banda muerta (del Universal)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     max_episode_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m    \u001b[38;5;66;03m# L√≠mite de episodio (del Universal)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimulador h√≠brido de tanque creado\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF√≠sica real del tanque + funcionalidades universales\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: TankLevelSimulator.__init__() got an unexpected keyword argument 'dead_band'"
     ]
    }
   ],
   "source": [
    "## Crear Entorno y Agente DQN\n",
    "\n",
    "# Crear simulador h√≠brido de tanque\n",
    "tank = TankLevelSimulator(\n",
    "    tank_area=2.0,           # m¬≤ - √Årea del tanque\n",
    "    max_height=5.0,          # m - Altura m√°xima\n",
    "    max_inflow=10.0,         # L/s - Caudal m√°ximo\n",
    "    outflow_coeff=2.0,       # Coeficiente de salida\n",
    "    dt=1.0,                  # s - Paso de tiempo\n",
    "    noise_level=0.02,        # Ruido en medici√≥n\n",
    "    dead_band=0.1,           # m - Banda muerta (del Universal)\n",
    "    max_episode_steps=200    # L√≠mite de episodio (del Universal)\n",
    ")\n",
    "print(\"Simulador h√≠brido de tanque creado\")\n",
    "print(f\"F√≠sica real del tanque + funcionalidades universales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Espacio de acciones PID creado:\n",
      "  Kp: [ 0.1  3.4  6.7 10. ]\n",
      "  Ki: [0.01       1.67333333 3.33666667 5.        ]\n",
      "  Kd: [1.00000000e-03 6.67333333e-01 1.33366667e+00 2.00000000e+00]\n",
      "  Total acciones: 64\n",
      "üîÑ Red objetivo actualizada (step 0)\n",
      " Agente DQN creado:\n",
      "   Estados: 6\n",
      "   Acciones: 64\n",
      "   Learning rate: 0.001\n",
      "   Gamma: 0.99\n",
      "Agente DQN creado\n",
      "  Acciones discretas: 64\n",
      "  Epsilon inicial: 1.000\n",
      "  Memoria disponible: 0\n"
     ]
    }
   ],
   "source": [
    "# Crear agente DQN\n",
    "agent = DQN_Agent(\n",
    "    state_dim=6,           # [level, setpoint, error, prev_error, integral, derivative]\n",
    "    lr=0.001,             # Learning rate\n",
    "    gamma=0.99,           # Discount factor\n",
    "    epsilon_start=1.0,    # Exploraci√≥n inicial\n",
    "    epsilon_end=0.01,     # Exploraci√≥n final\n",
    "    epsilon_decay=0.995,  # Decaimiento\n",
    "    memory_size=1000,     # Buffer peque√±o para pruebas\n",
    "    batch_size=32,\n",
    "    target_update_freq=50, # Actualizar target m√°s frecuente\n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "print(\"Agente DQN creado\")\n",
    "print(f\"  Acciones discretas: {agent.n_actions}\")\n",
    "print(f\"  Epsilon inicial: {agent.get_epsilon():.3f}\")\n",
    "print(f\"  Memoria disponible: {len(agent.memory)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Probando selecci√≥n de acciones (agente no entrenado)...\n",
      "Estado de prueba: [2.  3.  1.  0.8 5.  0.2]\n",
      "  Acci√≥n 1: √çndice= 9, PID=[0.10, 3.34, 0.67]\n",
      "  Acci√≥n 2: √çndice=25, PID=[3.40, 3.34, 0.67]\n",
      "  Acci√≥n 3: √çndice= 5, PID=[0.10, 1.67, 0.67]\n",
      "  Acci√≥n 4: √çndice=19, PID=[3.40, 0.01, 2.00]\n",
      "  Acci√≥n 5: √çndice= 6, PID=[0.10, 1.67, 1.33]\n",
      "\n",
      "üé≤ Epsilon actual: 1.000 (alta exploraci√≥n = acciones aleatorias)\n"
     ]
    }
   ],
   "source": [
    "# Probar selecci√≥n de acciones sin entrenar\n",
    "print(\" Probando selecci√≥n de acciones (agente no entrenado)...\")\n",
    "\n",
    "# Estado de prueba\n",
    "test_state = np.array([2.0, 3.0, 1.0, 0.8, 5.0, 0.2])  # [level, setpoint, error, prev_error, integral, derivative]\n",
    "print(f\"Estado de prueba: {test_state}\")\n",
    "\n",
    "# Probar varias acciones\n",
    "for i in range(5):\n",
    "    pid_params = agent.select_action(test_state, training=True)\n",
    "    action_idx = agent.get_last_action_index()\n",
    "    \n",
    "    print(f\"  Acci√≥n {i+1}: √çndice={action_idx:2d}, PID=[{pid_params[0]:.2f}, {pid_params[1]:.2f}, {pid_params[2]:.2f}]\")\n",
    "\n",
    "print(f\"\\nüé≤ Epsilon actual: {agent.get_epsilon():.3f} (alta exploraci√≥n = acciones aleatorias)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_episode(agent, tank, max_steps=50):\n",
    "    \"\"\"\n",
    "    Entrenar un episodio con simulador h√≠brido\n",
    "    \"\"\"\n",
    "    obs, info = tank.reset()\n",
    "    total_reward = 0\n",
    "    \n",
    "    for step in range(max_steps):\n",
    "        # Acci√≥n PID del agente\n",
    "        action = agent.select_action(obs, training=True)\n",
    "        next_obs, reward, done, truncated, info = tank.step(action)\n",
    "        \n",
    "        agent.store_experience(obs, action, reward, next_obs, done)\n",
    "        agent.update()\n",
    "        \n",
    "        total_reward += reward\n",
    "        obs = next_obs\n",
    "        \n",
    "        if done or truncated:\n",
    "            break\n",
    "    \n",
    "    return total_reward\n",
    "\n",
    "print(\"Funci√≥n de entrenamiento h√≠brida lista\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar episodio de prueba\n",
    "print(\"Entrenando episodio de prueba con simulador h√≠brido...\")\n",
    "print(f\"Memoria inicial: {len(agent.memory)} experiencias\")\n",
    "print(f\"Epsilon inicial: {agent.get_epsilon():.3f}\")\n",
    "\n",
    "total_reward = train_episode(agent, tank, max_steps=50)\n",
    "\n",
    "print(f\"Episodio completado:\")\n",
    "print(f\"  Recompensa total: {total_reward:.2f}\")\n",
    "print(f\"  Memoria final: {len(agent.memory)} experiencias\")\n",
    "print(f\"  Epsilon final: {agent.get_epsilon():.3f}\")\n",
    "print(f\"  F√≠sica del tanque: √Årea={tank.tank_area}m¬≤, Altura={tank.max_height}m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta celda ser√° reemplazada por la celda 11 que usa el tanque h√≠brido\n",
    "\n",
    "print(\"Usar la celda siguiente que entrena con simulador h√≠brido...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta celda ser√° reemplazada por la celda 12 que visualiza el h√≠brido\n",
    "\n",
    "print(\"Usar la celda siguiente que visualiza resultados del tanque h√≠brido...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar m√∫ltiples episodios con tanque h√≠brido\n",
    "NUM_EPISODES = 10\n",
    "\n",
    "print(f\"Entrenando {NUM_EPISODES} episodios con simulador h√≠brido...\")\n",
    "print(f\"Cada episodio simula f√≠sica real del tanque\")\n",
    "print(f\"Ecuaci√≥n: A * dh/dt = Qin - Qout (donde Qout = C * ‚àöh)\")\n",
    "\n",
    "results = []\n",
    "for episode in range(NUM_EPISODES):\n",
    "    total_reward = train_episode(agent, tank, max_steps=30)\n",
    "    \n",
    "    tank_info = tank.get_tank_info()\n",
    "    \n",
    "    results.append({\n",
    "        'episode': episode + 1,\n",
    "        'total_reward': total_reward,\n",
    "        'epsilon': agent.get_epsilon(),\n",
    "        'memory_size': len(agent.memory),\n",
    "        'final_level': tank_info['level'],\n",
    "        'final_error': tank_info['error']\n",
    "    })\n",
    "    \n",
    "    print(f\"Episodio {episode+1}: Reward={total_reward:.2f}, \"\n",
    "          f\"Nivel final={tank_info['level']:.2f}m, Error={tank_info['error']:.3f}m\")\n",
    "\n",
    "print(\"Entrenamiento completado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar resultados del entrenamiento h√≠brido\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# Recompensa por episodio\n",
    "ax1.plot(df_results['episode'], df_results['total_reward'], 'bo-', linewidth=2)\n",
    "ax1.set_title('Evoluci√≥n de la Recompensa')\n",
    "ax1.set_xlabel('Episodio')\n",
    "ax1.set_ylabel('Recompensa Total')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Epsilon decay\n",
    "ax2.plot(df_results['episode'], df_results['epsilon'], 'ro-', linewidth=2)\n",
    "ax2.set_title('Decaimiento de Epsilon')\n",
    "ax2.set_xlabel('Episodio')\n",
    "ax2.set_ylabel('Epsilon')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Nivel final por episodio\n",
    "ax3.plot(df_results['episode'], df_results['final_level'], 'go-', linewidth=2)\n",
    "ax3.axhline(y=tank.setpoint, color='r', linestyle='--', label='Setpoint')\n",
    "ax3.set_title('Nivel Final por Episodio')\n",
    "ax3.set_xlabel('Episodio')\n",
    "ax3.set_ylabel('Nivel (m)')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Error final por episodio\n",
    "ax4.plot(df_results['episode'], np.abs(df_results['final_error']), 'mo-', linewidth=2)\n",
    "ax4.axhline(y=tank.dead_band, color='g', linestyle='--', label='Banda muerta')\n",
    "ax4.set_title('Error Final por Episodio')\n",
    "ax4.set_xlabel('Episodio')\n",
    "ax4.set_ylabel('|Error| (m)')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Recompensa inicial: {df_results['total_reward'].iloc[0]:.2f}\")\n",
    "print(f\"Recompensa final: {df_results['total_reward'].iloc[-1]:.2f}\")\n",
    "print(f\"Error final promedio: {np.abs(df_results['final_error']).mean():.3f}m\")\n",
    "print(f\"Banda muerta del tanque: {tank.dead_band}m\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
