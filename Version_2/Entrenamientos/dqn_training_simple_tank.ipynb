{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f1db0a0",
   "metadata": {},
   "source": [
    "# TANQUE SIMPLE\n",
    "\n",
    "En esta notebook estudio el comportamiento en el caso mas simple de la industria, el llenado de un tanque mediante una entrada y una salida.\n",
    "\n",
    "## Balance de masa:\n",
    "A=E-S+G-C\n",
    "\n",
    "En este caso, al tratarse de un caso simple, la tasa de evaporacion de egua se desprecia, por lo que no hay ni consumo (C) ni generacion (G), resultando en :\n",
    "\n",
    "A= E-S\n",
    "\n",
    "Siendo la Entrada y Salida en caudales, puede re arreglarse la ecuacion para epresarla en aaltura, que es lo que se busca controlar: \n",
    "\n",
    "Area * dh/dt = Qin - Qout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a098d40",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ca96d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports completados\n",
      "PyTorch version: 2.2.2\n",
      "Device disponible: cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from typing import Dict, Any, List\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')  # Subir un nivel para acceder a las carpetas\n",
    "\n",
    "# Imports del proyecto\n",
    "from Environment.simulation_env import SimulationPIDEnv # Ambiente de simulaci√≥n PID\n",
    "from Simuladores.tanque_simple import TankSimulator # Simulador de tanque simple\n",
    "from Agentes.DQN.algorithm_DQN import DQNAgent  # Agente DQN\n",
    "\n",
    "# Configuraci√≥n de matplotlib\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úÖ Imports completados\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device disponible: {'cuda' if torch.cuda.is_available() else 'cpu'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "784c3c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvidia-smi\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1d61026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your runtime has 8.6 gigabytes of available RAM\n",
      "\n",
      "To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"\n",
      "menu, and then select High-RAM in the Runtime shape dropdown. Then, \n",
      "re-execute this cell.\n"
     ]
    }
   ],
   "source": [
    "from psutil import virtual_memory\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
    "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
    "  print('re-execute this cell.')\n",
    "else:\n",
    "  print('You are using a high-RAM runtime!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3065af64",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m      3\u001b[0m DEVICE \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDEVICE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/cuda/__init__.py:293\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    289\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    291\u001b[0m     )\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    296\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    297\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "torch.zeros(1).cuda()\n",
    "\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Running on {DEVICE}\")\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "print(\"Cuda Available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f57c8ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ac720fb",
   "metadata": {},
   "source": [
    "## 2. CONFIGURACI√ìN DE HIPERPAR√ÅMETROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc34b0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n del experimento\n",
    "config = {\n",
    "    # Identificaci√≥n\n",
    "    'experiment_name': 'dqn_tank_control',\n",
    "    'run_name': 'baseline_v1',\n",
    "    \n",
    "    # Ambiente\n",
    "    'env': {\n",
    "        'upper_range': 10.0,\n",
    "        'lower_range': 0.0,\n",
    "        'setpoint': 5.0,\n",
    "        'dead_band': 0.2,\n",
    "        'max_episode_steps': 200,\n",
    "        'dt': 1.0\n",
    "    },\n",
    "    \n",
    "    # Simulador de tanque\n",
    "    'tank': {\n",
    "        'area': 1.0,\n",
    "        'cv': 0.1,\n",
    "        'max_height': 10.0,\n",
    "        'max_flow_in': 0.5,\n",
    "        'dt': 1.0\n",
    "    },\n",
    "    \n",
    "    # Agente DQN\n",
    "    'agent': {\n",
    "        'state_dim': 6,\n",
    "        'action_dim': 7,\n",
    "        'hidden_dims': (128, 128, 64),\n",
    "        'lr': 0.001,\n",
    "        'gamma': 0.99,\n",
    "        'epsilon_start': 1.0,\n",
    "        'epsilon_min': 0.01,\n",
    "        'epsilon_decay': 0.995,\n",
    "        'memory_size': 10000,\n",
    "        'batch_size': 64,\n",
    "        'target_update_freq': 100,\n",
    "        'device': 'cpu'\n",
    "    },\n",
    "    \n",
    "    # Entrenamiento\n",
    "    'training': {\n",
    "        'n_episodes': 100,\n",
    "        'log_interval': 10,      # Logear cada N episodios\n",
    "        'save_interval': 50,     # Guardar modelo cada N episodios\n",
    "        'eval_interval': 25,     # Evaluar cada N episodios\n",
    "        'n_eval_episodes': 5     # Episodios para evaluaci√≥n\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Configuraci√≥n definida\")\n",
    "print(f\"\\nExperimento: {config['experiment_name']}\")\n",
    "print(f\"Run: {config['run_name']}\")\n",
    "print(f\"Episodios de entrenamiento: {config['training']['n_episodes']}\")\n",
    "print(f\"Hidden layers: {config['agent']['hidden_dims']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fca78a",
   "metadata": {},
   "source": [
    "## 3. INICIALIZAR WEIGHTS & BIASES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064f4751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar W&B \n",
    "wandb.init(\n",
    "    project=config['experiment_name'],\n",
    "    name=config['run_name'],\n",
    "    config=config,\n",
    "    tags=['dqn', 'tank-control', 'pid-tuning']\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Weights & Biases inicializado\")\n",
    "print(f\"Dashboard: {wandb.run.get_url()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ada61d",
   "metadata": {},
   "source": [
    "## 4. Ambiente y Simulador de Tanque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa90ebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear ambiente de simulaci√≥n\n",
    "env = SimulationPIDEnv(\n",
    "    config=config['env'],\n",
    "    control_mode='pid_tuning'\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Ambiente creado\")\n",
    "\n",
    "# Crear simulador de tanque\n",
    "tank = TankSimulator(\n",
    "    area=config['tank']['area'],\n",
    "    cv=config['tank']['cv'],\n",
    "    max_height=config['tank']['max_height'],\n",
    "    max_flow_in=config['tank']['max_flow_in'],\n",
    "    dt=config['tank']['dt']\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Simulador de tanque creado\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19cb55e",
   "metadata": {},
   "source": [
    "## 5. AGENTE DQN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d9bd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Crear agente DQN\n",
    "agent = DQNAgent(\n",
    "    state_dim=config['agent']['state_dim'],\n",
    "    action_dim=config['agent']['action_dim'],\n",
    "    hidden_dims=config['agent']['hidden_dims'],\n",
    "    lr=config['agent']['lr'],\n",
    "    gamma=config['agent']['gamma'],\n",
    "    epsilon_start=config['agent']['epsilon_start'],\n",
    "    epsilon_min=config['agent']['epsilon_min'],\n",
    "    epsilon_decay=config['agent']['epsilon_decay'],\n",
    "    memory_size=config['agent']['memory_size'],\n",
    "    batch_size=config['agent']['batch_size'],\n",
    "    target_update_freq=config['agent']['target_update_freq'],\n",
    "    device=config['agent']['device']\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Agente DQN creado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668bc08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar arquitectura de la red\n",
    "print(\"\\nüìê Arquitectura de la Red Q:\")\n",
    "print(agent.q_network)\n",
    "\n",
    "print(f\"\\nüìä Par√°metros totales: {sum(p.numel() for p in agent.q_network.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b89dee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar estad√≠sticas iniciales del agente\n",
    "stats = agent.get_stats()\n",
    "\n",
    "print(\"\\nüìà Estad√≠sticas del Agente:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5b87f6",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f52698",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN_Network_V1(nn.Module):    \n",
    "    def __init__(self, state_dim=6, n_actions=64, hidden_size=128):\n",
    "        super(DQN_Network_V1, self).__init__()\n",
    "        \n",
    "        # Arquitectura de la red - \n",
    "        self.fc1 = nn.Linear(state_dim, hidden_size)      # 6 ‚Üí 128\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)    # 128 ‚Üí 128  \n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size//2) # 128 ‚Üí 64\n",
    "        self.fc4 = nn.Linear(hidden_size//2, n_actions)   # 64 ‚Üí n_actions\n",
    "        \n",
    "        # Activaci√≥n\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Inicializar pesos\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Inicializar pesos de manera inteligente\"\"\"\n",
    "        for layer in [self.fc1, self.fc2, self.fc3, self.fc4]:\n",
    "            nn.init.kaiming_normal_(layer.weight)\n",
    "            nn.init.constant_(layer.bias, 0.01)\n",
    "    \n",
    "    def forward(self, state):\n",
    "        # Asegurar que sea tensor\n",
    "        if not isinstance(state, torch.Tensor):\n",
    "            state = torch.FloatTensor(state)\n",
    "        \n",
    "        # Si es un solo estado, agregar dimensi√≥n batch\n",
    "        if len(state.shape) == 1:\n",
    "            state = state.unsqueeze(0)\n",
    "        \n",
    "        # Paso a trav√©s de la red\n",
    "        x = self.relu(self.fc1(state))    # 6 ‚Üí 128 + ReLU\n",
    "        x = self.relu(self.fc2(x))        # 128 ‚Üí 128 + ReLU\n",
    "        x = self.relu(self.fc3(x))        # 128 ‚Üí 64 + ReLU\n",
    "        q_values = self.fc4(x)            # 64 ‚Üí n_actions (sin activaci√≥n)\n",
    "        \n",
    "        return q_values\n",
    "\n",
    "BATCH_SIZE=32    \n",
    "summary(DQN_Network_V1(3, 2), input_size=(BATCH_SIZE, 3, 500, 500))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
