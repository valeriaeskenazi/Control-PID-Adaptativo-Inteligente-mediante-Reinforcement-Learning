{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UK5zdOg132M"
      },
      "source": [
        "# W&B Sweep — DQN\n",
        "Búsqueda de hiperparámetros para el agente DQN en el ambiente Simple (CSTR).\n",
        "- Método: Random Search\n",
        "- Proyecto W&B: `Tesis_DQN`\n",
        "- Arquitectura: Simple (CTRL únicamente)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7tUe0S-132Q"
      },
      "source": [
        "## 1. Instalación e Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txHDg3zJ132R",
        "outputId": "78c678a6-d3ec-4dcf-ba5c-cbadd711e8c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imports completados\n",
            "PyTorch: 2.10.0+cu128\n",
            "Device: CUDA\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import wandb\n",
        "import sys\n",
        "\n",
        "# Agregar path del proyecto\n",
        "sys.path.append('../../')\n",
        "\n",
        "from Environment.Simulation_Env.Reactor_CSTR import CSTRSimulator\n",
        "from Environment.PIDControlEnv_simple import PIDControlEnv_Simple\n",
        "from Agente.DQN.train_DQN import DQNTrainer\n",
        "from Aux.Plots import SimplePlotter, print_summary\n",
        "\n",
        "print('Imports completados')\n",
        "print(f'PyTorch: {torch.__version__}')\n",
        "print(f'Device: {\"CUDA\" if torch.cuda.is_available() else \"CPU\"}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0eUimwd132S"
      },
      "source": [
        "## 2. Login W&B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eQmacKOi132Q"
      },
      "outputs": [],
      "source": [
        "!pip install wandb --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcSGG-Go132S",
        "outputId": "5a8da257-6351-4c12-8a7f-0e14ecf43687"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from /root/.netrc.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mve326684\u001b[0m (\u001b[33mve326684-universidad-ort-uruguay\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9U6XI1lQ132S"
      },
      "source": [
        "## 3. Configuración del Sweep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04L6X-MY132S",
        "outputId": "28623ca0-67ab-4c68-eb95-d1144e03ca20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: m3p9a8rm\n",
            "Sweep URL: https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN/sweeps/m3p9a8rm\n",
            "Sweep creado: m3p9a8rm\n"
          ]
        }
      ],
      "source": [
        "WANDB_TEAM    = 've326684-universidad-ort-uruguay'\n",
        "WANDB_PROJECT = 'Tesis_DQN'\n",
        "\n",
        "sweep_config = {\n",
        "    'name':   'dqn_cstr_random_search',\n",
        "    'method': 'random',\n",
        "\n",
        "    'metric': {\n",
        "        'name': 'eval_reward',\n",
        "        'goal': 'maximize'\n",
        "    },\n",
        "\n",
        "    'parameters': {\n",
        "\n",
        "        # ============ AMBIENTE ============\n",
        "        'max_time_detector': {'values': [15, 30, 60]},\n",
        "        'max_steps':         {'values': [20, 50, 100]},\n",
        "        'reward_dead_band':  {'values': [0.01, 0.02, 0.05]},\n",
        "        'delta_percent_ctrl':{'values': [0.1, 0.2, 0.3]},\n",
        "\n",
        "        # Reward weights — combinaciones predefinidas\n",
        "        'reward_weights_idx': {\n",
        "            'values': [0, 1, 2, 3]  # índice a la lista definida en sweep_run()\n",
        "        },\n",
        "\n",
        "        # ============ CRITERIOS DE ESTABILIDAD ============\n",
        "        'error_increase_tolerance': {'values': [1.2, 1.5, 2.0]},\n",
        "        'max_sign_changes_ratio':   {'values': [0.1, 0.2, 0.3]},\n",
        "        'max_abrupt_change_ratio':  {'values': [0.03, 0.05, 0.1]},\n",
        "        'abrupt_change_threshold':  {'values': [0.2, 0.3, 0.5]},\n",
        "\n",
        "        # ============ AGENTE DQN ============\n",
        "        'hidden_dims_idx':    {'values': [0, 1, 2, 3]},  # índice a lista en sweep_run()\n",
        "        'lr':                 {'values': [0.0001, 0.001, 0.01]},\n",
        "        'epsilon_decay':      {'values': [0.99, 0.995, 0.999]},\n",
        "        'target_update_freq': {'values': [50, 100, 200]},\n",
        "        'batch_size':         {'values': [32, 64, 128]},\n",
        "        'buffer_type':        {'values': ['simple', 'priority']},\n",
        "        'buffer_size':        {'values': [5000, 10000, 50000]},\n",
        "    }\n",
        "}\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, project=WANDB_PROJECT, entity=WANDB_TEAM)\n",
        "print(f'Sweep creado: {sweep_id}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cquBEU8132T"
      },
      "source": [
        "## 4. Función de Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "egOKAZMD132T"
      },
      "outputs": [],
      "source": [
        "# ============ LISTAS DE OPCIONES PREDEFINIDAS ============\n",
        "\n",
        "REWARD_WEIGHTS_OPTIONS = [\n",
        "    {'error': 1.0, 'tiempo': 0.3, 'overshoot': 0.2, 'energy': 0.1},   # 0: balanceado (default)\n",
        "    {'error': 2.0, 'tiempo': 0.1, 'overshoot': 0.5, 'energy': 0.1},   # 1: foco en error y overshoot\n",
        "    {'error': 1.0, 'tiempo': 0.5, 'overshoot': 0.1, 'energy': 0.5},   # 2: foco en tiempo y energía\n",
        "    {'error': 3.0, 'tiempo': 0.1, 'overshoot': 0.1, 'energy': 0.05},  # 3: solo error importa\n",
        "]\n",
        "\n",
        "HIDDEN_DIMS_OPTIONS = [\n",
        "    (64, 32),\n",
        "    (128, 64),\n",
        "    (128, 128, 64),\n",
        "    (256, 128, 64),\n",
        "]\n",
        "\n",
        "# ============ FIJOS PARA TODOS LOS RUNS ============\n",
        "SEED             = 42\n",
        "N_EPISODES       = 1000\n",
        "EVAL_FREQUENCY   = 50\n",
        "EARLY_STOPPING_PATIENCE   = 10\n",
        "EARLY_STOPPING_MIN_DELTA_PCT = 0.01\n",
        "N_MANIPULABLE_VARS = 2\n",
        "MANIPULABLE_RANGES = [(300, 420), (99.5, 104)]\n",
        "VAR_NAMES          = ['T (K)', 'V (m³)']\n",
        "DT                 = 1.0\n",
        "DEVICE             = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "\n",
        "def sweep_run():\n",
        "    # -------- Inicializar run --------\n",
        "    wandb.init()\n",
        "    cfg = wandb.config\n",
        "\n",
        "    # -------- Reproducibilidad --------\n",
        "    random.seed(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    torch.manual_seed(SEED)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(SEED)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark     = False\n",
        "    wandb.config.update({'seed': SEED}, allow_val_change=True)\n",
        "\n",
        "    # -------- Resolver índices --------\n",
        "    reward_weights = REWARD_WEIGHTS_OPTIONS[cfg.reward_weights_idx]\n",
        "    hidden_dims    = HIDDEN_DIMS_OPTIONS[cfg.hidden_dims_idx]\n",
        "\n",
        "    # Loggear valores reales (no índices) para legibilidad en W&B\n",
        "    wandb.config.update({\n",
        "        'reward_weights': str(reward_weights),\n",
        "        'hidden_dims':    str(hidden_dims),\n",
        "    }, allow_val_change=True)\n",
        "\n",
        "    # -------- Configurar CSTR --------\n",
        "    cstr = CSTRSimulator(\n",
        "        dt=DT,\n",
        "        control_limits=(MANIPULABLE_RANGES[0], MANIPULABLE_RANGES[1])\n",
        "    )\n",
        "\n",
        "    # -------- Construir config del trainer --------\n",
        "    trainer_config = {\n",
        "        # === AMBIENTE ===\n",
        "        'env_config': {\n",
        "            'architecture':    'simple',\n",
        "            'env_type':        'simulation',\n",
        "            'n_manipulable_vars': N_MANIPULABLE_VARS,\n",
        "            'manipulable_ranges': MANIPULABLE_RANGES,\n",
        "            'manipulable_setpoints': None,  # random en cada episodio\n",
        "            'dt_usuario':      DT,\n",
        "            'max_steps':       cfg.max_steps,\n",
        "            'max_time_detector': cfg.max_time_detector,\n",
        "            'reward_dead_band':  cfg.reward_dead_band,\n",
        "            'delta_percent_ctrl': cfg.delta_percent_ctrl,\n",
        "            'reward_weights':  reward_weights,\n",
        "            'pid_limits': [\n",
        "                (0.01, 50.0),\n",
        "                (0.001, 1.0),\n",
        "                (0.0,   1.0)\n",
        "            ],\n",
        "            'agent_controller_config': {'agent_type': 'discrete'},\n",
        "            'env_type_config': {\n",
        "                'dt': DT,\n",
        "                'control_limits': (MANIPULABLE_RANGES[0], MANIPULABLE_RANGES[1])\n",
        "            },\n",
        "            # Criterios de estabilidad\n",
        "            'stability_config': {\n",
        "                'error_increase_tolerance': cfg.error_increase_tolerance,\n",
        "                'max_sign_changes_ratio':   cfg.max_sign_changes_ratio,\n",
        "                'max_abrupt_change_ratio':  cfg.max_abrupt_change_ratio,\n",
        "                'abrupt_change_threshold':  cfg.abrupt_change_threshold,\n",
        "            },\n",
        "        },\n",
        "\n",
        "        # === AGENTE DQN ===\n",
        "        'agent_ctrl_config': {\n",
        "            'state_dim':          N_MANIPULABLE_VARS * 5,  # 5 features por variable\n",
        "            'action_dim':         7,\n",
        "            'n_vars':             N_MANIPULABLE_VARS,\n",
        "            'hidden_dims':        hidden_dims,\n",
        "            'lr':                 cfg.lr,\n",
        "            'gamma':              0.99,\n",
        "            'epsilon_start':      1.0,\n",
        "            'epsilon_min':        0.01,\n",
        "            'epsilon_decay':      cfg.epsilon_decay,\n",
        "            'batch_size':         cfg.batch_size,\n",
        "            'target_update_freq': cfg.target_update_freq,\n",
        "            'buffer_type':        cfg.buffer_type,\n",
        "            'buffer_size':        cfg.buffer_size,\n",
        "            'device':             DEVICE,\n",
        "            'seed':               SEED,\n",
        "        },\n",
        "\n",
        "        # === ENTRENAMIENTO ===\n",
        "        'n_episodes':          N_EPISODES,\n",
        "        'eval_frequency':      EVAL_FREQUENCY,\n",
        "        'save_frequency':      9999,  # no guardar checkpoints en sweep\n",
        "        'log_frequency':       50,\n",
        "        'checkpoint_dir':      f'checkpoints/dqn_{wandb.run.name}',\n",
        "        'early_stopping_patience':      EARLY_STOPPING_PATIENCE,\n",
        "        'early_stopping_min_delta_pct': EARLY_STOPPING_MIN_DELTA_PCT,\n",
        "        'use_wandb': True,\n",
        "    }\n",
        "\n",
        "    # -------- Conectar CSTR al ambiente --------\n",
        "    # Se hace después de crear el trainer para acceder al proceso\n",
        "    trainer = DQNTrainer(trainer_config)\n",
        "    trainer.env.proceso.connect_external_process(cstr)\n",
        "\n",
        "    # -------- Entrenar --------\n",
        "    trainer.train()\n",
        "\n",
        "    # -------- Métricas finales del run --------\n",
        "    wandb.log({\n",
        "        'final_eval_reward':  trainer.best_reward,\n",
        "        'total_episodes':     len(trainer.episode_rewards),\n",
        "        'final_epsilon':      trainer.epsilons[-1] if trainer.epsilons else 0,\n",
        "        'final_reward_mean10': np.mean(trainer.episode_rewards[-10:]),\n",
        "        'final_energy_mean10': np.mean(trainer.episode_energies[-10:]),\n",
        "        'final_overshoot_mean10': np.mean(trainer.episode_max_overshoots[-10:]),\n",
        "    })\n",
        "\n",
        "    print(f'Run completado: {wandb.run.name}')\n",
        "    wandb.finish()\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2D6k1gNr132U"
      },
      "source": [
        "## 5. Lanzar Sweep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uuvRp-TW132U",
        "outputId": "592d128f-5a1d-4726-f337-939503a3c4b4"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 563ca4uo with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tabrupt_change_threshold: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbuffer_size: 5000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbuffer_type: priority\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdelta_percent_ctrl: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepsilon_decay: 0.999\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \terror_increase_tolerance: 1.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dims_idx: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.01\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_abrupt_change_ratio: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_sign_changes_ratio: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_steps: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_time_detector: 30\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \treward_dead_band: 0.01\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \treward_weights_idx: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_update_freq: 200\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from /root/.netrc.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.25.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20260301_150612-563ca4uo</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN/runs/563ca4uo' target=\"_blank\">exalted-sweep-1</a></strong> to <a href='https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN/sweeps/m3p9a8rm' target=\"_blank\">https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN/sweeps/m3p9a8rm</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN' target=\"_blank\">https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN/sweeps/m3p9a8rm' target=\"_blank\">https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN/sweeps/m3p9a8rm</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN/runs/563ca4uo' target=\"_blank\">https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN/runs/563ca4uo</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/Agente/memory.py:198: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)\n",
            "  next_states = torch.FloatTensor([e.next_state for e in batch]).to(self.device)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Episodio 0/1000\n",
            "  Reward: -36.01\n",
            "  Length: 50\n",
            "  CTRL Loss: 147084.3216\n",
            "  CTRL Epsilon: 0.9812\n",
            "\n",
            "Episodio 50/1000\n",
            "  Reward: -1.50\n",
            "  Length: 50\n",
            "  CTRL Loss: 6741.7268\n",
            "  CTRL Epsilon: 0.0804\n",
            "Evaluación: Reward promedio = -119.53\n",
            "Agente guardado en: checkpoints/dqn_exalted-sweep-1/agent_ctrl_best.pt\n",
            "Checkpoint guardado: best\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 50 that is less than the current step 51. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Episodio 100/1000\n",
            "  Reward: -15.32\n",
            "  Length: 50\n",
            "  CTRL Loss: 21535.7710\n",
            "  CTRL Epsilon: 0.0100\n",
            "Evaluación: Reward promedio = -35.77\n",
            "Agente guardado en: checkpoints/dqn_exalted-sweep-1/agent_ctrl_best.pt\n",
            "Checkpoint guardado: best\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 100 that is less than the current step 101. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Episodio 150/1000\n",
            "  Reward: -52.85\n",
            "  Length: 50\n",
            "  CTRL Loss: 37824.6468\n",
            "  CTRL Epsilon: 0.0100\n",
            "Evaluación: Reward promedio = -53.00\n",
            "  Sin mejora: 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 150 that is less than the current step 151. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Episodio 200/1000\n",
            "  Reward: -142.00\n",
            "  Length: 50\n",
            "  CTRL Loss: 39262.9959\n",
            "  CTRL Epsilon: 0.0100\n",
            "Evaluación: Reward promedio = -156.13\n",
            "  Sin mejora: 2/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 200 that is less than the current step 201. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Episodio 250/1000\n",
            "  Reward: -77.12\n",
            "  Length: 50\n",
            "  CTRL Loss: 84200.4486\n",
            "  CTRL Epsilon: 0.0100\n",
            "Evaluación: Reward promedio = -112.71\n",
            "  Sin mejora: 3/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 250 that is less than the current step 251. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Episodio 300/1000\n",
            "  Reward: -187.21\n",
            "  Length: 50\n",
            "  CTRL Loss: 46576.9602\n",
            "  CTRL Epsilon: 0.0100\n",
            "Evaluación: Reward promedio = -150.88\n",
            "  Sin mejora: 4/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 300 that is less than the current step 301. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Episodio 350/1000\n",
            "  Reward: -136.47\n",
            "  Length: 50\n",
            "  CTRL Loss: 65459.1659\n",
            "  CTRL Epsilon: 0.0100\n",
            "Evaluación: Reward promedio = -136.29\n",
            "  Sin mejora: 5/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 350 that is less than the current step 351. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Episodio 400/1000\n",
            "  Reward: -2.50\n",
            "  Length: 50\n",
            "  CTRL Loss: 156367.0036\n",
            "  CTRL Epsilon: 0.0100\n",
            "Evaluación: Reward promedio = -136.01\n",
            "  Sin mejora: 6/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 400 that is less than the current step 401. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Episodio 450/1000\n",
            "  Reward: -67.42\n",
            "  Length: 50\n",
            "  CTRL Loss: 182735.9682\n",
            "  CTRL Epsilon: 0.0100\n",
            "Evaluación: Reward promedio = -114.81\n",
            "  Sin mejora: 7/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 450 that is less than the current step 451. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Episodio 500/1000\n",
            "  Reward: -79.37\n",
            "  Length: 50\n",
            "  CTRL Loss: 141367.1048\n",
            "  CTRL Epsilon: 0.0100\n",
            "Evaluación: Reward promedio = -73.36\n",
            "  Sin mejora: 8/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 500 that is less than the current step 501. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Episodio 550/1000\n",
            "  Reward: -71.61\n",
            "  Length: 50\n",
            "  CTRL Loss: 503483.8845\n",
            "  CTRL Epsilon: 0.0100\n",
            "Evaluación: Reward promedio = -161.28\n",
            "  Sin mejora: 9/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 550 that is less than the current step 551. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Episodio 600/1000\n",
            "  Reward: -37.76\n",
            "  Length: 50\n",
            "  CTRL Loss: 446648.9527\n",
            "  CTRL Epsilon: 0.0100\n",
            "Evaluación: Reward promedio = -41.65\n",
            "  Sin mejora: 10/10\n",
            "Early stopping en episodio 600\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>energy</td><td>▁▁▁▁▁▃█▇▁▁████████████████▁▁▆██▁███▁▁▁▁▁</td></tr><tr><td>epsilon</td><td>█▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval_reward</td><td>▃█▇▁▄▂▂▂▄▆▁█</td></tr><tr><td>final_energy_mean10</td><td>▁</td></tr><tr><td>final_epsilon</td><td>▁</td></tr><tr><td>final_eval_reward</td><td>▁</td></tr><tr><td>final_overshoot_mean10</td><td>▁</td></tr><tr><td>final_reward_mean10</td><td>▁</td></tr><tr><td>kd_var0</td><td>▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>kd_var1</td><td>▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>+8</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>energy</td><td>15343271.56193</td></tr><tr><td>epsilon</td><td>0.01</td></tr><tr><td>eval_reward</td><td>-41.64907</td></tr><tr><td>final_energy_mean10</td><td>15322114.15934</td></tr><tr><td>final_epsilon</td><td>0.01</td></tr><tr><td>final_eval_reward</td><td>-35.76563</td></tr><tr><td>final_overshoot_mean10</td><td>2.48983</td></tr><tr><td>final_reward_mean10</td><td>-22.24951</td></tr><tr><td>kd_var0</td><td>0.0</td></tr><tr><td>kd_var1</td><td>0.0</td></tr><tr><td>+8</td><td>...</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">exalted-sweep-1</strong> at: <a href='https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN/runs/563ca4uo' target=\"_blank\">https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN/runs/563ca4uo</a><br> View project at: <a href='https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN' target=\"_blank\">https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20260301_150612-563ca4uo/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/wandb/agents/pyagent.py\", line 304, in _run_job\n",
            "    self._function()\n",
            "  File \"/tmp/ipython-input-8490/3235770438.py\", line 144, in sweep_run\n",
            "    print(f'Run completado: {wandb.run.name}')\n",
            "                             ^^^^^^^^^^^^^^\n",
            "AttributeError: 'NoneType' object has no attribute 'name'\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 563ca4uo errored: 'NoneType' object has no attribute 'name'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fw299qso with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tabrupt_change_threshold: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbuffer_size: 50000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbuffer_type: priority\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdelta_percent_ctrl: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepsilon_decay: 0.99\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \terror_increase_tolerance: 1.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dims_idx: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.01\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_abrupt_change_ratio: 0.05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_sign_changes_ratio: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_steps: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_time_detector: 30\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \treward_dead_band: 0.05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \treward_weights_idx: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_update_freq: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from /root/.netrc.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.25.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20260301_163947-fw299qso</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN/runs/fw299qso' target=\"_blank\">denim-sweep-2</a></strong> to <a href='https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN/sweeps/m3p9a8rm' target=\"_blank\">https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN/sweeps/m3p9a8rm</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN' target=\"_blank\">https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN/sweeps/m3p9a8rm' target=\"_blank\">https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN/sweeps/m3p9a8rm</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN/runs/fw299qso' target=\"_blank\">https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN/runs/fw299qso</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episodio 0/1000\n",
            "  Reward: -88.13\n",
            "  Length: 100\n",
            "  CTRL Loss: 64329.5985\n",
            "  CTRL Epsilon: 0.6894\n",
            "\n",
            "Episodio 50/1000\n",
            "  Reward: -2.82\n",
            "  Length: 100\n",
            "  CTRL Loss: 304127.7835\n",
            "  CTRL Epsilon: 0.0100\n",
            "Evaluación: Reward promedio = -41.08\n",
            "Agente guardado en: checkpoints/dqn_denim-sweep-2/agent_ctrl_best.pt\n",
            "Checkpoint guardado: best\n",
            "\n",
            "Episodio 100/1000\n",
            "  Reward: -221.74\n",
            "  Length: 100\n",
            "  CTRL Loss: 4616912.0956\n",
            "  CTRL Epsilon: 0.0100\n",
            "Evaluación: Reward promedio = -293.10\n",
            "  Sin mejora: 1/10\n",
            "\n",
            "Episodio 150/1000\n",
            "  Reward: -374.16\n",
            "  Length: 100\n",
            "  CTRL Loss: 28516929.8350\n",
            "  CTRL Epsilon: 0.0100\n",
            "Evaluación: Reward promedio = -324.63\n",
            "  Sin mejora: 2/10\n",
            "\n",
            "Episodio 200/1000\n",
            "  Reward: -169.05\n",
            "  Length: 100\n",
            "  CTRL Loss: 180774340.2000\n",
            "  CTRL Epsilon: 0.0100\n",
            "Evaluación: Reward promedio = -147.23\n",
            "  Sin mejora: 3/10\n",
            "\n",
            "Episodio 250/1000\n",
            "  Reward: -135.21\n",
            "  Length: 100\n",
            "  CTRL Loss: 427356543.9600\n",
            "  CTRL Epsilon: 0.0100\n",
            "Evaluación: Reward promedio = -131.86\n",
            "  Sin mejora: 4/10\n",
            "\n",
            "Episodio 300/1000\n",
            "  Reward: -406.59\n",
            "  Length: 100\n",
            "  CTRL Loss: 1562656078.0800\n",
            "  CTRL Epsilon: 0.0100\n",
            "Evaluación: Reward promedio = -328.45\n",
            "  Sin mejora: 5/10\n",
            "\n",
            "Episodio 350/1000\n",
            "  Reward: -104.83\n",
            "  Length: 100\n",
            "  CTRL Loss: 4796747543.6800\n",
            "  CTRL Epsilon: 0.0100\n",
            "Evaluación: Reward promedio = -138.63\n",
            "  Sin mejora: 6/10\n",
            "\n",
            "Episodio 400/1000\n",
            "  Reward: -164.49\n",
            "  Length: 100\n",
            "  CTRL Loss: 10548116026.8800\n",
            "  CTRL Epsilon: 0.0100\n",
            "Evaluación: Reward promedio = -188.20\n",
            "  Sin mejora: 7/10\n",
            "\n",
            "Episodio 450/1000\n",
            "  Reward: -311.76\n",
            "  Length: 100\n",
            "  CTRL Loss: 24244976261.1200\n",
            "  CTRL Epsilon: 0.0100\n",
            "Evaluación: Reward promedio = -137.02\n",
            "  Sin mejora: 8/10\n",
            "\n",
            "Episodio 500/1000\n",
            "  Reward: -184.23\n",
            "  Length: 100\n",
            "  CTRL Loss: 60639606415.3600\n",
            "  CTRL Epsilon: 0.0100\n",
            "Evaluación: Reward promedio = -104.72\n",
            "  Sin mejora: 9/10\n",
            "\n",
            "Episodio 550/1000\n",
            "  Reward: -48.56\n",
            "  Length: 100\n",
            "  CTRL Loss: 92346084372.4800\n",
            "  CTRL Epsilon: 0.0100\n",
            "Evaluación: Reward promedio = -67.45\n",
            "  Sin mejora: 10/10\n",
            "Early stopping en episodio 550\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>energy</td><td>▂▁▁██▄█▄█▁▁▂████▇▄▇▁▇█▇██▇█▁▁████▄▁▄████</td></tr><tr><td>epsilon</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval_reward</td><td>█▂▁▅▆▁▆▄▆▆▇</td></tr><tr><td>final_energy_mean10</td><td>▁</td></tr><tr><td>final_epsilon</td><td>▁</td></tr><tr><td>final_eval_reward</td><td>▁</td></tr><tr><td>final_overshoot_mean10</td><td>▁</td></tr><tr><td>final_reward_mean10</td><td>▁</td></tr><tr><td>kd_var0</td><td>█▄█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▂█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>kd_var1</td><td>▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▄▃▁▁▁▁▁▁</td></tr><tr><td>+8</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>energy</td><td>60992866.25233</td></tr><tr><td>epsilon</td><td>0.01</td></tr><tr><td>eval_reward</td><td>-67.44721</td></tr><tr><td>final_energy_mean10</td><td>64735560.18882</td></tr><tr><td>final_epsilon</td><td>0.01</td></tr><tr><td>final_eval_reward</td><td>-41.08065</td></tr><tr><td>final_overshoot_mean10</td><td>7.64246</td></tr><tr><td>final_reward_mean10</td><td>-159.05013</td></tr><tr><td>kd_var0</td><td>0.0</td></tr><tr><td>kd_var1</td><td>0.0</td></tr><tr><td>+8</td><td>...</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">denim-sweep-2</strong> at: <a href='https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN/runs/fw299qso' target=\"_blank\">https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN/runs/fw299qso</a><br> View project at: <a href='https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN' target=\"_blank\">https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20260301_163947-fw299qso/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/wandb/agents/pyagent.py\", line 304, in _run_job\n",
            "    self._function()\n",
            "  File \"/tmp/ipython-input-8490/3235770438.py\", line 144, in sweep_run\n",
            "    print(f'Run completado: {wandb.run.name}')\n",
            "                             ^^^^^^^^^^^^^^\n",
            "AttributeError: 'NoneType' object has no attribute 'name'\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run fw299qso errored: 'NoneType' object has no attribute 'name'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: baeyl2g2 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tabrupt_change_threshold: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbuffer_size: 10000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbuffer_type: simple\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdelta_percent_ctrl: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepsilon_decay: 0.999\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \terror_increase_tolerance: 1.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dims_idx: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.01\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_abrupt_change_ratio: 0.05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_sign_changes_ratio: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_steps: 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_time_detector: 15\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \treward_dead_band: 0.02\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \treward_weights_idx: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_update_freq: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from /root/.netrc.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.25.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20260301_190622-baeyl2g2</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN/runs/baeyl2g2' target=\"_blank\">whole-sweep-3</a></strong> to <a href='https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN/sweeps/m3p9a8rm' target=\"_blank\">https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN/sweeps/m3p9a8rm</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN' target=\"_blank\">https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN/sweeps/m3p9a8rm' target=\"_blank\">https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN/sweeps/m3p9a8rm</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN/runs/baeyl2g2' target=\"_blank\">https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN/runs/baeyl2g2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episodio 0/1000\n",
            "  Reward: -30.88\n",
            "  Length: 20\n",
            "  CTRL Loss: 0.0000\n",
            "  CTRL Epsilon: 1.0000\n",
            "\n",
            "Episodio 50/1000\n",
            "  Reward: -4.00\n",
            "  Length: 20\n",
            "  CTRL Loss: 937.0982\n",
            "  CTRL Epsilon: 0.3718\n",
            "Evaluación: Reward promedio = -6.85\n",
            "Agente guardado en: checkpoints/dqn_whole-sweep-3/agent_ctrl_best.pt\n",
            "Checkpoint guardado: best\n",
            "\n",
            "Episodio 100/1000\n",
            "  Reward: -16.36\n",
            "  Length: 20\n",
            "  CTRL Loss: 14894.3767\n",
            "  CTRL Epsilon: 0.1367\n",
            "Evaluación: Reward promedio = -17.33\n",
            "  Sin mejora: 1/10\n",
            "\n",
            "Episodio 150/1000\n",
            "  Reward: -4.55\n",
            "  Length: 20\n",
            "  CTRL Loss: 21182.6911\n",
            "  CTRL Epsilon: 0.0503\n",
            "Evaluación: Reward promedio = -8.58\n",
            "  Sin mejora: 2/10\n",
            "\n",
            "Episodio 200/1000\n",
            "  Reward: -11.10\n",
            "  Length: 20\n",
            "  CTRL Loss: 94371.7623\n",
            "  CTRL Epsilon: 0.0185\n",
            "Evaluación: Reward promedio = -12.59\n",
            "  Sin mejora: 3/10\n",
            "\n",
            "Episodio 250/1000\n",
            "  Reward: -3.75\n",
            "  Length: 20\n",
            "  CTRL Loss: 198505.6420\n",
            "  CTRL Epsilon: 0.0100\n",
            "Evaluación: Reward promedio = -10.24\n",
            "  Sin mejora: 4/10\n",
            "\n",
            "Episodio 300/1000\n",
            "  Reward: -27.32\n",
            "  Length: 20\n",
            "  CTRL Loss: 252624.9389\n",
            "  CTRL Epsilon: 0.0100\n",
            "Evaluación: Reward promedio = -31.05\n",
            "  Sin mejora: 5/10\n",
            "\n",
            "Episodio 350/1000\n",
            "  Reward: -50.54\n",
            "  Length: 20\n",
            "  CTRL Loss: 1213087.0773\n",
            "  CTRL Epsilon: 0.0100\n",
            "Evaluación: Reward promedio = -25.66\n",
            "  Sin mejora: 6/10\n",
            "\n",
            "Episodio 400/1000\n",
            "  Reward: -11.50\n",
            "  Length: 20\n",
            "  CTRL Loss: 1990982.8906\n",
            "  CTRL Epsilon: 0.0100\n",
            "Evaluación: Reward promedio = -13.98\n",
            "  Sin mejora: 7/10\n",
            "\n",
            "Episodio 450/1000\n",
            "  Reward: -17.77\n",
            "  Length: 20\n",
            "  CTRL Loss: 5541308.3937\n",
            "  CTRL Epsilon: 0.0100\n",
            "Evaluación: Reward promedio = -27.70\n",
            "  Sin mejora: 8/10\n",
            "\n",
            "Episodio 500/1000\n",
            "  Reward: -8.71\n",
            "  Length: 20\n",
            "  CTRL Loss: 12436582.1625\n",
            "  CTRL Epsilon: 0.0100\n",
            "Evaluación: Reward promedio = -8.93\n",
            "  Sin mejora: 9/10\n",
            "\n",
            "Episodio 550/1000\n",
            "  Reward: -4.94\n",
            "  Length: 20\n",
            "  CTRL Loss: 37791765.1250\n",
            "  CTRL Epsilon: 0.0100\n",
            "Evaluación: Reward promedio = -10.53\n",
            "  Sin mejora: 10/10\n",
            "Early stopping en episodio 550\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>energy</td><td>▇▇▇▇▇▇▇▇▇█▇▇▇▇▇█▁▇▇▇▇▇█▇▇▇█▇▇▇██▇▇▇▇▇▇▇█</td></tr><tr><td>epsilon</td><td>█▆▄▄▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval_reward</td><td>█▅▇▆▇▁▃▆▂▇▇</td></tr><tr><td>final_energy_mean10</td><td>▁</td></tr><tr><td>final_epsilon</td><td>▁</td></tr><tr><td>final_eval_reward</td><td>▁</td></tr><tr><td>final_overshoot_mean10</td><td>▁</td></tr><tr><td>final_reward_mean10</td><td>▁</td></tr><tr><td>kd_var0</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>kd_var1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▂▁███▆█▁▁▁</td></tr><tr><td>+8</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>energy</td><td>1293442.71691</td></tr><tr><td>epsilon</td><td>0.01</td></tr><tr><td>eval_reward</td><td>-10.53435</td></tr><tr><td>final_energy_mean10</td><td>1385539.28348</td></tr><tr><td>final_epsilon</td><td>0.01</td></tr><tr><td>final_eval_reward</td><td>-6.8479</td></tr><tr><td>final_overshoot_mean10</td><td>8.02044</td></tr><tr><td>final_reward_mean10</td><td>-21.54996</td></tr><tr><td>kd_var0</td><td>0.0</td></tr><tr><td>kd_var1</td><td>6e-05</td></tr><tr><td>+8</td><td>...</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">whole-sweep-3</strong> at: <a href='https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN/runs/baeyl2g2' target=\"_blank\">https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN/runs/baeyl2g2</a><br> View project at: <a href='https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN' target=\"_blank\">https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20260301_190622-baeyl2g2/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/wandb/agents/pyagent.py\", line 304, in _run_job\n",
            "    self._function()\n",
            "  File \"/tmp/ipython-input-8490/3235770438.py\", line 144, in sweep_run\n",
            "    print(f'Run completado: {wandb.run.name}')\n",
            "                             ^^^^^^^^^^^^^^\n",
            "AttributeError: 'NoneType' object has no attribute 'name'\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run baeyl2g2 errored: 'NoneType' object has no attribute 'name'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tn8pb4ae with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tabrupt_change_threshold: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbuffer_size: 5000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbuffer_type: simple\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdelta_percent_ctrl: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepsilon_decay: 0.999\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \terror_increase_tolerance: 1.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dims_idx: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_abrupt_change_ratio: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_sign_changes_ratio: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_steps: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_time_detector: 60\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \treward_dead_band: 0.02\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \treward_weights_idx: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_update_freq: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from /root/.netrc.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.25.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20260301_191507-tn8pb4ae</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN/runs/tn8pb4ae' target=\"_blank\">glorious-sweep-4</a></strong> to <a href='https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN/sweeps/m3p9a8rm' target=\"_blank\">https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN/sweeps/m3p9a8rm</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN' target=\"_blank\">https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN/sweeps/m3p9a8rm' target=\"_blank\">https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN/sweeps/m3p9a8rm</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN/runs/tn8pb4ae' target=\"_blank\">https://wandb.ai/ve326684-universidad-ort-uruguay/Tesis_DQN/runs/tn8pb4ae</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episodio 0/1000\n",
            "  Reward: -41.48\n",
            "  Length: 100\n",
            "  CTRL Loss: 0.0000\n",
            "  CTRL Epsilon: 1.0000\n",
            "\n",
            "Episodio 50/1000\n",
            "  Reward: -26.62\n",
            "  Length: 100\n",
            "  CTRL Loss: 3046.6725\n",
            "  CTRL Epsilon: 0.0100\n",
            "Evaluación: Reward promedio = -53.49\n",
            "Agente guardado en: checkpoints/dqn_glorious-sweep-4/agent_ctrl_best.pt\n",
            "Checkpoint guardado: best\n",
            "\n",
            "Episodio 100/1000\n",
            "  Reward: -223.26\n",
            "  Length: 100\n",
            "  CTRL Loss: 59075.3368\n",
            "  CTRL Epsilon: 0.0100\n",
            "Evaluación: Reward promedio = -236.27\n",
            "  Sin mejora: 1/10\n"
          ]
        }
      ],
      "source": [
        "wandb.agent(sweep_id, function=sweep_run, count=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyyGunBt132U"
      },
      "source": [
        "## 6. Visualización local del mejor run\n",
        "Ejecutar DESPUÉS de que termine el sweep."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47HeSnZv132V"
      },
      "outputs": [],
      "source": [
        "from Aux.Plots import SimplePlotter, print_summary\n",
        "\n",
        "# Recuperar el mejor run del sweep\n",
        "api = wandb.Api()\n",
        "sweep = api.sweep(f'{WANDB_TEAM}/{WANDB_PROJECT}/{sweep_id}')\n",
        "best_run = sorted(sweep.runs, key=lambda r: r.summary.get('eval_reward', -float('inf')), reverse=True)[0]\n",
        "\n",
        "print(f'Mejor run: {best_run.name}')\n",
        "print(f'eval_reward: {best_run.summary.get(\"eval_reward\"):.4f}')\n",
        "print(f'Hiperparámetros:')\n",
        "for k, v in best_run.config.items():\n",
        "    print(f'  {k}: {v}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}